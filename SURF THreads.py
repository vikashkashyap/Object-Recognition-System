
import cv2
import numpy as np
import sys
from threading import Thread
from imutils.video import FPS
import imutils

import gc
gc.collect()



MIN_MATCH_COUNT=30


surf = cv2.xfeatures2d.SURF_create()

FLANN_INDEX_KDITREE=0
flannParam=dict(algorithm=FLANN_INDEX_KDITREE,tree=5)
flann=cv2.FlannBasedMatcher(flannParam,{})

trainImg=cv2.imread("AI project/1.jpg",0)
trainKP,trainDesc=surf.detectAndCompute(trainImg,None)

class WebcamVideoStream:
	def __init__(self, src=0):
		# initialize the video camera stream and read the first frame
		# from the stream
		self.stream = cv2.VideoCapture(src)
		(self.grabbed, self.frame) = self.stream.read()

		# initialize the variable used to indicate if the thread should
		# be stopped
		self.stopped = False

	def start(self):
		# start the thread to read frames from the video stream
		t = Thread(target=self.update, args=())
		t.daemon = True
		t.start()
		return self

	def update(self):
		# keep looping infinitely until the thread is stopped
		while True:
			# if the thread indicator variable is set, stop the thread
			if self.stopped:
				return

			# otherwise, read the next frame from the stream
			(self.grabbed, self.frame) = self.stream.read()

	def read(self):
		# return the frame most recently read
		return self.frame

	def stop(self):
		# indicate that the thread should be stopped
		self.stream.release()
		self.stopped = True

vs = WebcamVideoStream(src=0).start()
fps = FPS().start()
while True:
    
    frame = vs.read()
    frame = imutils.resize(frame, width=600)
    
    
    QueryImg=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    queryKP,queryDesc=surf.detectAndCompute(QueryImg,None)
    matches=flann.knnMatch(queryDesc,trainDesc,k=2)

    goodMatch=[]
    for m,n in matches:
        if(m.distance<0.75*n.distance):
            goodMatch.append(m)
    if(len(goodMatch)>MIN_MATCH_COUNT):
        tp=[]
        qp=[]
        for m in goodMatch:
            tp.append(trainKP[m.trainIdx].pt)
            qp.append(queryKP[m.queryIdx].pt)
        tp,qp=np.float32((tp,qp))
        H,status=cv2.findHomography(tp,qp,cv2.RANSAC,3.0)
        
        ########checking for empty H#######
        if H.any():
            h,w=trainImg.shape
            trainBorder=np.float32([[[0,0],[0,h-1],[w-1,h-1],[w-1,0]]])
            queryBorder=cv2.perspectiveTransform(trainBorder,H)
            cv2.polylines(frame,[np.int32(queryBorder)],True,(0,255,0),5)
    else:
            print ("Not Enough match found- %d/%d"%(len(goodMatch),MIN_MATCH_COUNT))
                  
    cv2.imshow("result",frame)
                  
    if cv2.waitKey(10)==ord('q'):
        break
    fps.update()

fps.stop()
print("[INFO] elasped time: {:.2f}".format(fps.elapsed()))
print("[INFO] approx. FPS: {:.2f}".format(fps.fps()))
cv2.destroyAllWindows()
vs.stop()



